# Hands-on learning LLM internals with Claude

This is a human learning project, performed with specific use of AI tools.

I learn best through hands-on building and experimentation. In this project, I worked with Claude Code only as a tutor. The functional Rust code is largely written by my hands, standing on the shoulders of giants through the use of PyTorch. The role of Claude was to teach me what I didn't know (or know well).

Claude provided an architecture and implementation plan for LLM training and inference, which I then implemented. Throughout the process, Claude would answer my questions (Socratically), and write unit tests after I was done to confirm that the code worked as intended. 

Occasionally, I asked Claude to stub out function signatures and docs for me when we got into really new domains. I would ask for explanations of the concepts, and avoided accepting too many concepts blindly (though many I did -- I'm not an ML engineer after this effort alone).

It was fun and very convenient to have an always-on, ready-when-you-are, custom tutor. I think this is the future of learning for certain people who, like me, learn well by building labs. Vibe-learning, if you will.

See [PLAN.md](./PLAN.md) for details about what I built.

# Why?

> "You don't have to be an engineer to be be a racing driver, but you do have to have Mechanical Sympathy." 
  - *Jackie Stewart, racing driver*

[Mechanical sympathy](https://en.wiktionary.org/wiki/mechanical_sympathy) is the idea that one is more effective with a tool when they understand how the tool works. The originating quote had to do with the automobile, in the context of competitive driving. But the same concept extends to any tool, from aircraft to circular saws. I believe AI, specifically LLMs and their descendents, are the Jacquard loom of knowledge work. Understanding its internal workings yields insights that are valuable in application of the tool.